# Quick Setup Guide

This guide will help you get the Population Health Analytics Dashboard running on your local machine in under 10 minutes.

## Prerequisites Checklist

- [ ] Python 3.8+ installed
- [ ] Google Cloud Platform account
- [ ] GCP Project created
- [ ] Billing enabled on GCP project

## Step 1: Google Cloud Setup (5 minutes)

### 1.1 Enable Required APIs

Go to your GCP Console and enable:
- BigQuery API
- Vertex AI API

```bash
# Or use gcloud CLI:
gcloud services enable bigquery.googleapis.com
gcloud services enable aiplatform.googleapis.com
```

### 1.2 Create Service Account

1. Navigate to **IAM & Admin** → **Service Accounts**
2. Click **Create Service Account**
3. Name: `health-analytics-service`
4. Grant roles:
   - BigQuery Data Viewer
   - BigQuery Job User
   - Vertex AI User
5. Click **Done**
6. Click on the service account → **Keys** → **Add Key** → **Create New Key** (JSON)
7. Download and save the JSON file securely

### 1.3 Set Up BigQuery Dataset

```sql
-- Create dataset
CREATE SCHEMA `your-project-id.pop_health_dataset`;

-- Upload your health data tables to this dataset
-- Create a unified view joining all your health data tables
```

## Step 2: Local Environment Setup (3 minutes)

### 2.1 Clone Repository

```bash
git clone https://github.com/oinsarkar/population-health-ai-analytics.git
cd population-health-ai-analytics
```

### 2.2 Create Virtual Environment

```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 2.3 Install Dependencies

```bash
pip install -r requirements.txt
```

### 2.4 Configure Authentication

**Windows PowerShell:**
```powershell
$env:GOOGLE_APPLICATION_CREDENTIALS="C:\path\to\your\service-account-key.json"
```

**macOS/Linux:**
```bash
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
```

### 2.5 Update Configuration

Edit `app.py` and update:
```python
PROJECT_ID = "your-gcp-project-id"
DATASET_ID = "pop_health_dataset"
TABLE_ID = "unified_health_view"
```

## Step 3: Run the Application (1 minute)

```bash
streamlit run app.py
```

Your browser should automatically open to `http://localhost:8501`

## Troubleshooting

### Issue: "streamlit command not found"
```bash
python -m streamlit run app.py
```

### Issue: Authentication errors
- Verify your service account key path is correct
- Check that the environment variable is set in the current terminal session
- Ensure your service account has the required permissions

### Issue: BigQuery connection fails
- Verify BigQuery API is enabled
- Check that your dataset and table names are correct
- Ensure your service account has BigQuery permissions

### Issue: Vertex AI model not found
- Try different regions: `us-central1`, `us-west1`, `us-east1`
- Ensure Vertex AI API is enabled
- Check service account has Vertex AI User role

## Verification Steps

1. **Test BigQuery Connection:**
```python
from google.cloud import bigquery
client = bigquery.Client()
print("Connected successfully!")
```

2. **Test Vertex AI:**
```python
import vertexai
from vertexai.generative_models import GenerativeModel

vertexai.init(project="your-project-id", location="us-west1")
model = GenerativeModel("gemini-1.5-flash")
print("Vertex AI initialized!")
```

## Next Steps

- Customize the dashboard layout
- Add your own health metrics
- Deploy to Google Cloud Run for production use
- Set up CI/CD pipeline

## Getting Help

If you encounter issues:
1. Check the [main README](README.md) for detailed documentation
2. Review error messages carefully
3. Open an issue on GitHub with:
   - Error message
   - Steps to reproduce
   - Your Python and package versions

## Security Reminders

⚠️ **Never commit your service account key to Git**
⚠️ **Add `*.json` to your `.gitignore` file**
⚠️ **Store credentials securely**
